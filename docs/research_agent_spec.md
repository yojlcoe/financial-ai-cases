# ResearchAgent ä»•æ§˜æ›¸

**æœ€çµ‚æ›´æ–°**: 2025-01-05
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.0

---

## ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
3. [å‡¦ç†ãƒ•ãƒ­ãƒ¼](#å‡¦ç†ãƒ•ãƒ­ãƒ¼)
4. [AIé–¢é€£æ€§åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯](#AIé–¢é€£æ€§åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯)
5. [ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼](#ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼)
6. [ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°](#ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)
7. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§)
8. [è¨­å®šé …ç›®](#è¨­å®šé …ç›®)
9. [APIä»•æ§˜](#APIä»•æ§˜)
10. [æ”¹å–„å±¥æ­´](#æ”¹å–„å±¥æ­´)

---

## æ¦‚è¦

### ç›®çš„

ResearchAgentã¯ã€é‡‘èæ©Ÿé–¢ã®AIäº‹ä¾‹ã‚’è‡ªå‹•åé›†ãƒ»åˆ†æã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã™ã€‚è¤‡æ•°ã®æƒ…å ±æºï¼ˆWebæ¤œç´¢ã€ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ï¼‰ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—ã—ã€LLMã‚’ç”¨ã„ã¦AIé–¢é€£æ€§ã‚’åˆ¤å®šã€åˆ†é¡ã€è¦ç´„ã‚’è¡Œã„ã¾ã™ã€‚

### ä¸»è¦æ©Ÿèƒ½

1. **å¤šæºæƒ…å ±åé›†**
   - DuckDuckGo Webæ¤œç´¢ï¼ˆæ—¥æœ¬èªãƒ»è‹±èªã‚¯ã‚¨ãƒªï¼‰
   - ä¼æ¥­å…¬å¼ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã®è‡ªå‹•ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°

2. **AIé–¢é€£æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**
   - 2æ®µéšåˆ¤å®š: æœ¬æ–‡ â†’ ã‚¿ã‚¤ãƒˆãƒ«+ã‚¹ãƒ‹ãƒšãƒƒãƒˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
   - LLMä¸å¯æ™‚ã¯åˆ¤å®šã‚’ä¿ç•™ã—ã€è¨˜äº‹å‡¦ç†ã‚’ç¶™ç¶š

3. **è¨˜äº‹å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**
   - PDF/HTMLè‡ªå‹•åˆ¤åˆ¥ãƒ»æŠ½å‡º
   - æ—¥ä»˜è‡ªå‹•æŠ½å‡ºï¼ˆHTMLè§£æ â†’ LLM â†’ å½“æ—¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
   - ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ãƒ»è¦ç´„ç”Ÿæˆ
   - é‡è¤‡æ’é™¤ï¼ˆURLæ­£è¦åŒ– + æ—¢å­˜URLãƒã‚§ãƒƒã‚¯ï¼‰

4. **ã‚¸ãƒ§ãƒ–ç®¡ç†**
   - éåŒæœŸãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
   - é€²æ—ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ï¼ˆä¼æ¥­æ•°ãƒ»è¨˜äº‹æ•°ï¼‰
   - ã‚¨ãƒ©ãƒ¼æ™‚ã®éƒ¨åˆ†çš„ç¶™ç¶š

---

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      API Layer                               â”‚
â”‚  POST /jobs/start, POST /articles/from-url, etc.            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   ResearchAgent         â”‚
        â”‚  (Orchestrator)         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                         â”‚
        â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Crawler Layer â”‚                       â”‚  Parser Layer  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - DuckDuckGo  â”‚                       â”‚ - ArticleFetch â”‚
â”‚ - PressScrape â”‚                       â”‚ - PdfExtractor â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚    LLM Layer      â”‚
                â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                â”‚ - Relevance       â”‚
                â”‚ - Classifier      â”‚
                â”‚ - Summarizer      â”‚
                â”‚ - DateExtractor   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Database Layer   â”‚
                â”‚  (CRUD + Models)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¾å­˜ã‚µãƒ¼ãƒ“ã‚¹

| ã‚µãƒ¼ãƒ“ã‚¹ | å½¹å‰² | ãƒ•ã‚¡ã‚¤ãƒ« |
|---------|------|---------|
| **DuckDuckGoSearcher** | Webæ¤œç´¢å®Ÿè¡Œ | `app/services/crawler/duckduckgo_search.py` |
| **PressScraper** | ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹å–å¾— | `app/services/crawler/press_scraper.py` |
| **ArticleFetcher** | è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ï¼ˆHTML/PDFï¼‰ | `app/services/parser/article_fetcher.py` |
| **PdfExtractor** | PDFè§£æ | `app/services/parser/pdf_extractor.py` |
| **AiRelevanceClassifier** | AIé–¢é€£æ€§åˆ¤å®š | `app/services/llm/relevance.py` |
| **ArticleClassifier** | ã‚«ãƒ†ã‚´ãƒªãƒ»ã‚¿ã‚°åˆ†é¡ | `app/services/llm/classifier.py` |
| **ArticleSummarizer** | è¦ç´„ç”Ÿæˆ | `app/services/llm/summarizer.py` |
| **DateExtractor** | æ—¥ä»˜æŠ½å‡º | `app/services/llm/date_extractor.py` |
| **OllamaClient** | LLM APIé€šä¿¡åŸºç›¤ | `app/services/llm/ollama_client.py` |
| **PromptTemplates** | ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç† | `app/services/llm/prompt_templates.py` |

---

## å‡¦ç†ãƒ•ãƒ­ãƒ¼

### ã‚¸ãƒ§ãƒ–å®Ÿè¡Œãƒ•ãƒ­ãƒ¼å…¨ä½“

```mermaid
graph TD
    A[POST /jobs/start] --> B[run_research_job]
    B --> C[ResearchAgent.run job_id]
    C --> D{ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®šå–å¾—}
    D -->|æˆåŠŸ| E{ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ä¼æ¥­å–å¾—}
    D -->|å¤±æ•—| Z[ã‚¸ãƒ§ãƒ–å¤±æ•—]
    E -->|0ä»¶| Z
    E -->|1ä»¶ä»¥ä¸Š| F[ã‚¸ãƒ§ãƒ–é€²æ—åˆæœŸåŒ–]
    F --> G[FOR EACH ä¼æ¥­]
    G --> H[_process_company]
    H --> I[DuckDuckGoæ¤œç´¢]
    H --> J[ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹å–å¾—]
    I --> K[_process_items_in_order]
    J --> K
    K --> L[URLæ­£è¦åŒ–ãƒ»é‡è¤‡æ’é™¤]
    L --> M[_fetch_and_process_article]
    M --> N{AIé–¢é€£?}
    N -->|No| O[ã‚¹ã‚­ãƒƒãƒ—]
    N -->|Yes| P[åˆ†é¡ãƒ»è¦ç´„]
    P --> Q[DBä¿å­˜]
    Q --> R[é€²æ—æ›´æ–°]
    R --> G
    G -->|å…¨ä¼æ¥­å®Œäº†| S[ã‚¸ãƒ§ãƒ–å®Œäº†]
```

### _fetch_and_process_article ã®è©³ç´°ãƒ•ãƒ­ãƒ¼

```
1. è¨˜äº‹å†…å®¹å–å¾—
   ArticleFetcher.fetch_content(url)
   â”œâ”€ HTTP GET
   â”œâ”€ Content-Typeåˆ¤å®š
   â”œâ”€ PDF â†’ PdfExtractor.extract_from_bytes()
   â””â”€ HTML â†’ BeautifulSoupè§£æ

2. AIé–¢é€£æ€§åˆ¤å®šï¼ˆ2æ®µéšï¼‰
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ if article_data.content exists: â”‚
   â”‚   â”œâ”€ classify_article_content() â”‚ â† æœ¬æ–‡ãƒ™ãƒ¼ã‚¹ï¼ˆå³å¯†ï¼‰
   â”‚   â”‚   â†’ False: return None      â”‚
   â”‚   â”‚   â†’ None:  è­¦å‘Šã®ã¿ç¶™ç¶š     â”‚
   â”‚   â””â”€ True: æ¬¡ã¸                 â”‚
   â”‚ else:                           â”‚
   â”‚   â”œâ”€ classify_text()            â”‚ â† ã‚¿ã‚¤ãƒˆãƒ«+ã‚¹ãƒ‹ãƒšãƒƒãƒˆï¼ˆè»½é‡ï¼‰
   â”‚   â”‚   â†’ False: return None      â”‚
   â”‚   â”‚   â†’ None:  è­¦å‘Šã®ã¿ç¶™ç¶š     â”‚
   â”‚   â””â”€ True: ç©ºcontentã§ä¿å­˜      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. æ—¥ä»˜æ¤œè¨¼
   published_date å–å¾—å„ªå…ˆé †ä½:
   1. article_data.published_date
   2. item.published_date (æ¤œç´¢çµæœ)
   3. DateExtractor.extract_date() (LLM)
   4. datetime.now().date() (æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)

   æ—¥ä»˜ç¯„å›²ãƒã‚§ãƒƒã‚¯:
   - source="manual" â†’ å¸¸ã«ä¿å­˜
   - source="duckduckgo" â†’ å¸¸ã«ä¿å­˜
   - source="press_list" ã‹ã¤ date_validated=true â†’ å†æ¤œè¨¼ã—ãªã„
   - ãã®ä»– â†’ start_date â‰¤ published_date â‰¤ end_date

4. LLMå‡¦ç†ï¼ˆé€æ¬¡å®Ÿè¡Œï¼‰
   â”œâ”€ summarizer.summarize()
   â”‚   â†’ summary, key_points, outcomes, technology
   â”‚
   â””â”€ classifier.classify()
       â†’ category, business_area, tags, is_inappropriate

5. DBä¿å­˜
   ArticleCreate â†’ crud_article.create_article()
   content ã¯ 5000æ–‡å­—ã¾ã§åˆ‡ã‚Šè©°ã‚
```

---

## AIé–¢é€£æ€§åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯

### åˆ¤å®šæˆ¦ç•¥

ResearchAgentã¯ **æœ¬æ–‡å„ªå…ˆãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹** ã®2æ®µéšåˆ¤å®šã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚

#### æ®µéš1: æœ¬æ–‡ãƒ™ãƒ¼ã‚¹åˆ¤å®šï¼ˆæ¨å¥¨ï¼‰

```python
if article_data and article_data.get("content"):
    is_ai_related = await ai_classifier.classify_article_content(
        title=article_data.get("title", title),
        content=content
    )
```

- **ä½¿ç”¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°**: è¨˜äº‹æœ¬æ–‡ã®å–å¾—ã«æˆåŠŸã—ãŸå ´åˆ
- **ç²¾åº¦**: é«˜ï¼ˆæœ¬æ–‡ã®å†…å®¹ã‚’åˆ†æï¼‰
- **å‡¦ç†æ™‚é–“**: LLMã®æ¨è«–æ™‚é–“ã«ä¾å­˜
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: `AI_RELEVANCE_CONTENT_PROMPT` (prompt_templates.py)
- **å‚™è€ƒ**: åˆ¤å®šæ™‚ã¯æœ¬æ–‡ã®å…ˆé ­1000æ–‡å­—ã‚’ä½¿ç”¨

#### æ®µéš2: ã‚¿ã‚¤ãƒˆãƒ«+ã‚¹ãƒ‹ãƒšãƒƒãƒˆåˆ¤å®šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

```python
else:
    is_ai_related = await ai_classifier.classify_text(
        title=title,
        snippet=snippet
    )
```

- **ä½¿ç”¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°**: æœ¬æ–‡å–å¾—å¤±æ•—æ™‚
- **ç²¾åº¦**: ä¸­ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¹ãƒ‹ãƒšãƒƒãƒˆã®ã¿ï¼‰
- **å‡¦ç†æ™‚é–“**: LLMã®æ¨è«–æ™‚é–“ã«ä¾å­˜
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: `AI_RELEVANCE_TEXT_PROMPT` (prompt_templates.py)

### åˆ¤å®šçµæœã®å‡¦ç†

| æˆ»ã‚Šå€¤ | æ„å‘³ | å‡¦ç† |
|--------|------|------|
| `True` | AIé–¢é€£ | å‡¦ç†ç¶™ç¶šï¼ˆåˆ†é¡ãƒ»è¦ç´„ï¼‰ |
| `False` | AIé–¢é€£ã§ãªã„ | è¨˜äº‹ã‚’ç ´æ£„ï¼ˆreturn Noneï¼‰ |
| `None` | åˆ¤å®šä¸å¯ï¼ˆLLMã‚¨ãƒ©ãƒ¼ç­‰ï¼‰ | è­¦å‘Šãƒ­ã‚°å‡ºåŠ› + å‡¦ç†ç¶™ç¶šï¼ˆä¿å®ˆçš„ï¼‰ |

### åˆ¤å®šåŸºæº–ï¼ˆLLMå´ï¼‰

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æŒ‡å®šã—ã¦ã„ã‚‹åŸºæº–:

- âœ… AIé–¢é€£: ç”ŸæˆAIã€æ©Ÿæ¢°å­¦ç¿’ã€AIæ´»ç”¨ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãªã©ã®å…·ä½“çš„è¨€åŠ
- âŒ ç„¡é–¢ä¿‚: DXã‚„ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ã®ã¿ã§AIã®å…·ä½“çš„è¨€åŠãŒãªã„è¨˜äº‹ã€ä¸€èˆ¬çš„ãªITæ›´æ–°

---

## ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

### æ¤œç´¢çµæœã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

#### DuckDuckGoæ¤œç´¢çµæœ

```python
{
    "url": "https://example.com/article",
    "title": "è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«",
    "snippet": "è¨˜äº‹ã®æ¦‚è¦...",
    "source": "duckduckgo"  # ResearchAgentãŒä»˜ä¸
}
```

#### ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹çµæœ

```python
{
    "url": "https://company.com/press/2025/01/news.html",
    "title": "ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«",
    "snippet": "",
    "published_date": date(2025, 1, 15),
    "date_validated": True,  # æ—¥ä»˜ç¯„å›²ãƒã‚§ãƒƒã‚¯æ¸ˆã¿
    "source": "press_list"
}
```

### ArticleFetcher ã®è¿”ã‚Šå€¤

```python
{
    "title": "æŠ½å‡ºã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«",
    "content": "æœ¬æ–‡ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœ€å¤§5000æ–‡å­—ï¼‰",
    "url": "å…ƒã®URL",
    "published_date": date(2025, 1, 15) | None
}
```

- **PDF**: `PdfExtractor` ã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º + ã‚¿ã‚¤ãƒˆãƒ«è‡ªå‹•æ¤œå‡º
- **HTML**: BeautifulSoupã§ã‚»ãƒ¬ã‚¯ã‚¿ãƒ™ãƒ¼ã‚¹æŠ½å‡º

### URLæ­£è¦åŒ–ãƒ«ãƒ¼ãƒ«

`_normalize_url()` ã§ä»¥ä¸‹ã‚’å®Ÿæ–½:

1. **è¿½è·¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‰Šé™¤**
   ```
   utm_source, utm_medium, gclid, fbclid, _ga ãªã©
   ```

2. **ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆå‰Šé™¤**
   ```
   https://example.com/article#section1
   â†’ https://example.com/article
   ```

3. **ãƒ‘ã‚¹ã®çµ±ä¸€**
   ```
   https://example.com/page/
   â†’ https://example.com/page
   ```

4. **å¤§æ–‡å­—å°æ–‡å­—ã®çµ±ä¸€**
   ```
   scheme ã¨ netloc ã‚’å°æ–‡å­—åŒ–
   ```

---

## ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ–¹é‡ï¼ˆv2.0ä»¥é™ï¼‰

#### å°å…¥æ¸ˆã¿ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ©Ÿæ§‹

1. **ServiceError éšå±¤**
   - `ServiceError`: åŸºåº•ã‚¯ãƒ©ã‚¹ï¼ˆservice_name, error_code, message, detailsï¼‰
   - `RetryableError`: ãƒªãƒˆãƒ©ã‚¤å¯èƒ½ãªã‚¨ãƒ©ãƒ¼
   - `NonRetryableError`: ãƒªãƒˆãƒ©ã‚¤ä¸å¯ã®ã‚¨ãƒ©ãƒ¼

2. **ErrorCode åˆ—æŒ™å‹**
   ```python
   ErrorCode.FETCH_TIMEOUT
   ErrorCode.LLM_UNAVAILABLE
   ErrorCode.PDF_EXTRACT_ERROR
   ```

3. **ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯**
   - `retry_async()` + `RetryConfig` ã‚’ `ArticleFetcher.fetch_content()` ã§ä½¿ç”¨
   - ä¾‹å¤–ç¨®åˆ¥ã«å¿œã˜ã¦æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§å†è©¦è¡Œ

#### ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®æŒ™å‹•

| ã‚¨ãƒ©ãƒ¼ç®‡æ‰€ | æŒ™å‹• | å½±éŸ¿ç¯„å›² |
|-----------|------|---------|
| æ¤œç´¢è¨­å®šå–å¾—å¤±æ•— | ã‚¸ãƒ§ãƒ–å…¨ä½“ã‚’å¤±æ•— | å…¨ä¼æ¥­ |
| ä¼æ¥­å‡¦ç†ã‚¨ãƒ©ãƒ¼ | è©²å½“ä¼æ¥­ã‚’ã‚¹ã‚­ãƒƒãƒ— | 1ä¼æ¥­ã®ã¿ |
| è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼ | ã‚¿ã‚¤ãƒˆãƒ«+ã‚¹ãƒ‹ãƒšãƒƒãƒˆåˆ¤å®šã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ | 1è¨˜äº‹ã®ã¿ |
| LLMåˆ¤å®šã‚¨ãƒ©ãƒ¼ (None) | è­¦å‘Šãƒ­ã‚° + å‡¦ç†ç¶™ç¶š | 1è¨˜äº‹ã®ã¿ |
| DBä¿å­˜ã‚¨ãƒ©ãƒ¼ | å½“è©²ä¼æ¥­ã®å‡¦ç†ã‚’ä¸­æ–­ã—æ¬¡ã®ä¼æ¥­ã¸ | 1ä¼æ¥­ã®ã¿ |

### ãƒ­ã‚°å‡ºåŠ›

ç¾åœ¨ã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«:

- `[INFO]`: æ­£å¸¸ãƒ•ãƒ­ãƒ¼ï¼ˆä¼æ¥­å‡¦ç†é–‹å§‹ã€è¨˜äº‹ä¿å­˜æˆåŠŸï¼‰
- `[WARN]`: æ½œåœ¨çš„å•é¡Œï¼ˆLLMåˆ¤å®šNoneã€æ—¥ä»˜æŠ½å‡ºå¤±æ•—ï¼‰
- `[FILTERED]`: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆAIé–¢é€£ã§ãªã„è¨˜äº‹ï¼‰
- `[ERROR]`: ã‚¨ãƒ©ãƒ¼ï¼ˆHTTPå¤±æ•—ã€DBä¿å­˜å¤±æ•—ï¼‰
- `[RETRY]`: ãƒªãƒˆãƒ©ã‚¤å®Ÿè¡Œ

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§

### å‡¦ç†æ™‚é–“ã®å‚¾å‘

- LLMå‘¼ã³å‡ºã—ï¼ˆAIé–¢é€£åˆ¤å®šãƒ»åˆ†é¡ãƒ»è¦ç´„ï¼‰ãŒæ”¯é…çš„
- è¦ç´„ã¯æœ¬æ–‡ãŒçŸ­ã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹
- è¦ç´„ â†’ åˆ†é¡ã®é †ã§é€æ¬¡å®Ÿè¡Œ

### ãƒ¬ãƒ¼ãƒˆåˆ¶é™

```python
await asyncio.sleep(3)  # ä¼æ¥­ã”ã¨
await asyncio.sleep(1)  # è¨˜äº‹ã”ã¨
```

### æœ€é©åŒ–ã®ä½™åœ°

1. **LLMå‘¼ã³å‡ºã—ã®ä¸¦åˆ—åŒ–**
   - ç¾åœ¨: è¦ç´„ãƒ»åˆ†é¡ã¯é€æ¬¡å®Ÿè¡Œ
   - æ”¹å–„: `asyncio.gather()` ã§ä¸¦åˆ—å®Ÿè¡Œ

2. **ãƒãƒƒãƒå‡¦ç†**
   - ç¾åœ¨: è¨˜äº‹ã”ã¨ã«DBä¿å­˜
   - æ”¹å–„: ãƒãƒƒãƒã‚¤ãƒ³ã‚µãƒ¼ãƒˆ â†’ DBè² è·è»½æ¸›

---

## è¨­å®šé …ç›®

### ScheduleSetting (DB)

```python
class ScheduleSetting:
    search_start_date: date    # æ¤œç´¢å¯¾è±¡ã®é–‹å§‹æ—¥
    search_end_date: date      # æ¤œç´¢å¯¾è±¡ã®çµ‚äº†æ—¥
    schedule_type: str         # daily / weekly
    schedule_day: int          # weekly: 0-6, daily: 1-28
    schedule_hour: int         # 0-23
```

### CompanySearchSettings (DB)

```python
class CompanySearchSettings:
    company_id: int
    region: str                # æ¤œç´¢ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆä¾‹: "jp-jp", "sg-en"ï¼‰
    custom_keywords: List[str] # ã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆResearchAgentã§ã¯æœªä½¿ç”¨ï¼‰
```

### SearchConfig (app/settings/search_config.py)

```python
class SearchConfig:
    search_keywords: List[str]          # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    default_region: Optional[str]       # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒªãƒ¼ã‚¸ãƒ§ãƒ³

### RegionKeywords (app/utils/region_keywords.py)

```python
def get_keywords_by_region(region: Optional[str]) -> List[str]:
    ...
```
```

---

## APIä»•æ§˜

### POST /jobs/start

**Request:**
```json
{
  "job_type": "manual"
}
```

**Response:**
```json
{
  "job_id": 123,
  "message": "Job started with 10 companies"
}
```

### POST /articles/from-url

æ‰‹å‹•URLè¿½åŠ ï¼ˆResearchAgentã‚’éƒ¨åˆ†çš„ã«ä½¿ç”¨ï¼‰

**Request:**
```json
{
  "company_id": 14,
  "url": "https://example.com/article"
}
```

**Response:**
```json
{
  "job_id": 230,
  "message": "URL addition job started for Sample Bank"
}
```

### POST /articles/from-urls

**Request:**
```json
{
  "company_id": 14,
  "urls": ["https://example.com/article-1", "https://example.com/article-2"]
}
```

**Response:**
```json
{
  "job_id": 231,
  "message": "2 URL(s) addition job started for Sample Bank"
}
```

---

## æ”¹å–„å±¥æ­´

### v2.0 (2025-01-05)

**æ–°æ©Ÿèƒ½:**
- âœ… å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹è¿½åŠ 
  - `DateParser`: æ—¥ä»˜è§£æçµ±ä¸€
  - `JSONExtractor`: JSONæŠ½å‡ºçµ±ä¸€
  - `HTTPClient`: HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆçµ±ä¸€
- âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°çµ±ä¸€
  - `ServiceError`, `RetryableError`, `NonRetryableError`
  - `ErrorCode` åˆ—æŒ™å‹
  - `retry_async()`, `@with_retry` ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
- âœ… AIé–¢é€£æ€§åˆ¤å®šã®æ˜ç¢ºåŒ–
  - æœ¬æ–‡å„ªå…ˆãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹ã®2æ®µéšåˆ¤å®šã‚’æ–‡æ›¸åŒ–

**ãƒã‚°ä¿®æ­£:**
- ğŸ› PDFæŠ½å‡ºå¾Œã®AIåˆ¤å®šãŒå‹•ä½œã—ãªã„å•é¡Œã‚’ä¿®æ­£
- ğŸ› prompt_templates.py ã®é‡è¤‡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‰Šé™¤

**ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:**
- ğŸ“ æœ¬ä»•æ§˜æ›¸ã‚’æ–°è¦ä½œæˆ
- ğŸ“ å‡¦ç†ãƒ•ãƒ­ãƒ¼ã®è©³ç´°å›³ã‚’è¿½åŠ 
- ğŸ“ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§ã‚’æ˜è¨˜

### v1.0 (2025-12)

**åˆæœŸãƒªãƒªãƒ¼ã‚¹:**
- DuckDuckGo + ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹çµ±åˆ
- LLMåˆ†é¡ãƒ»è¦ç´„æ©Ÿèƒ½
- URLæ­£è¦åŒ–ãƒ»é‡è¤‡æ’é™¤

---

## ä»˜éŒ²

### é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ—

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/v1/
â”‚   â”‚   â””â”€â”€ jobs.py                        # ã‚¸ãƒ§ãƒ–API
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ crawler/
â”‚   â”‚   â”‚   â”œâ”€â”€ research_agent.py          # â˜… ãƒ¡ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼
â”‚   â”‚   â”‚   â”œâ”€â”€ duckduckgo_search.py       # Webæ¤œç´¢
â”‚   â”‚   â”‚   â””â”€â”€ press_scraper.py           # ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹
â”‚   â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â”‚   â”œâ”€â”€ article_fetcher.py         # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—
â”‚   â”‚   â”‚   â””â”€â”€ pdf_extractor.py           # PDFè§£æ
â”‚   â”‚   â””â”€â”€ llm/
â”‚   â”‚       â”œâ”€â”€ ollama_client.py           # LLMåŸºç›¤
â”‚   â”‚       â”œâ”€â”€ relevance.py               # AIåˆ¤å®š
â”‚   â”‚       â”œâ”€â”€ classifier.py              # åˆ†é¡
â”‚   â”‚       â”œâ”€â”€ summarizer.py              # è¦ç´„
â”‚   â”‚       â”œâ”€â”€ date_extractor.py          # æ—¥ä»˜æŠ½å‡º
â”‚   â”‚       â””â”€â”€ prompt_templates.py        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†
â”‚   â”œâ”€â”€ utils/                              # â˜… v2.0 æ–°è¦è¿½åŠ 
â”‚   â”‚   â”œâ”€â”€ date_parser.py                 # æ—¥ä»˜è§£æçµ±ä¸€
â”‚   â”‚   â”œâ”€â”€ json_extractor.py              # JSONæŠ½å‡ºçµ±ä¸€
â”‚   â”‚   â”œâ”€â”€ http_client.py                 # HTTPçµ±ä¸€
â”‚   â”‚   â”œâ”€â”€ service_error.py               # ã‚¨ãƒ©ãƒ¼å®šç¾©
â”‚   â”‚   â””â”€â”€ retry_handler.py               # ãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹
â”‚   â”œâ”€â”€ crud/
â”‚   â”‚   â”œâ”€â”€ company.py
â”‚   â”‚   â”œâ”€â”€ article.py
â”‚   â”‚   â”œâ”€â”€ job.py
â”‚   â”‚   â””â”€â”€ schedule_setting.py
â”‚   â””â”€â”€ schemas/
â”‚       â””â”€â”€ article.py                     # ArticleCreate, ArticleUpdate
â””â”€â”€ scripts/
    â””â”€â”€ test_mufg_job.py                   # ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```

### ä»Šå¾Œã®æ”¹å–„äºˆå®š

1. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**
   - [ ] LLMå‘¼ã³å‡ºã—ã®ä¸¦åˆ—åŒ–ï¼ˆasyncio.gatherï¼‰
   - [ ] DBãƒãƒƒãƒä¿å­˜
   - [ ] LLMå¿œç­”ã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°

2. **æ©Ÿèƒ½è¿½åŠ **
   - [ ] æ§‹é€ åŒ–ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ï¼ˆJSONå½¢å¼ï¼‰
   - [ ] è¨˜äº‹ã®é¡ä¼¼åº¦åˆ¤å®šï¼ˆé‡è¤‡è¨˜äº‹æ’é™¤ï¼‰
   - [ ] æ®µéšçš„ã‚¸ãƒ§ãƒ–å†é–‹æ©Ÿèƒ½

3. **ã‚³ãƒ¼ãƒ‰å“è³ª**
   - [ ] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Š
   - [ ] å‹ãƒ’ãƒ³ãƒˆã®å®Œå…¨åŒ–
   - [ ] Docstring ã®å……å®Ÿ

---

**Document Version:** 2.0
**Last Updated:** 2025-01-05
**Maintained by:** Development Team
