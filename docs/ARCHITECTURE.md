# システムアーキテクチャ仕様書

## 概要

事例調査AIエージェントは、金融機関のAI・DX事例を自動収集・分析するシステムです。

**最終更新日:** 2025-12-30

---

## システム構成図

```
┌─────────────────────────────────────────────────────────────┐
│                         Frontend                            │
│                    (Next.js + React)                        │
│                                                             │
│  - 企業管理UI                                                │
│  - 記事閲覧UI                                                │
│  - ジョブ実行UI                                              │
│  - 検索設定UI ← 新規追加                                      │
│  - レポート生成UI                                            │
└──────────────────────┬──────────────────────────────────────┘
                       │ HTTP/REST API
                       │
┌──────────────────────▼──────────────────────────────────────┐
│                       Backend                               │
│                  (FastAPI + Python)                         │
│                                                             │
│  ┌─────────────┐  ┌──────────────┐  ┌─────────────────┐   │
│  │  API Layer  │  │   Services   │  │  Repositories   │   │
│  │             │  │              │  │                 │   │
│  │ - Companies │  │ - Crawler    │  │ - Company Repo  │   │
│  │ - Articles  │  │ - LLM Filter │  │ - Article Repo  │   │
│  │ - Jobs      │  │ - Scheduler  │  │ - Settings Repo │   │
│  │ - Settings  │  │ - Reporter   │  │                 │   │
│  └─────────────┘  └──────────────┘  └─────────────────┘   │
│                                                             │
└──────────────────────┬──────────────────────────────────────┘
                       │ SQLAlchemy ORM (async)
                       │
┌──────────────────────▼──────────────────────────────────────┐
│                    PostgreSQL                               │
│                                                             │
│  - companies                                                │
│  - source_urls                                              │
│  - articles                                                 │
│  - job_histories                                            │
│  - schedule_settings (スケジュール)                          │
│  - global_search_settings (検索キーワード・LLM)              │
│  - company_search_settings (企業別設定)                      │
└──────────────────────┬──────────────────────────────────────┘
                       │
┌──────────────────────▼──────────────────────────────────────┐
│                    External Services                        │
│                                                             │
│  - DuckDuckGo Search API                                    │
│  - Ollama (LLM: llama3.2:1b)                                │
│  - BeautifulSoup (Webスクレイピング)                         │
└─────────────────────────────────────────────────────────────┘
```

---

## 不適切記事フィルタリング・アーキテクチャ

### 概要

記事収集時に複数層のフィルタリングを行い、不適切な記事を早期に除外することで、LLM処理コストを削減し、データ品質を向上させています。

### フィルタリングの段階

```
検索結果取得
    │
    ▼
┌────────────────────────────────────┐
│ 1. URLレベルフィルタ（即時除外）    │
│   - リスト記事パターン検出          │
│   - 信頼性の低いソース検出          │
│   - URL正規化・重複チェック         │
└───────────┬────────────────────────┘
            │
            ▼
┌────────────────────────────────────┐
│ 2. AI関連性判定（LLM）             │
│   - 本文ベース判定（優先）          │
│   - タイトル+スニペット判定（FB）   │
│   - 厳格な基準で非AI記事を除外      │
└───────────┬────────────────────────┘
            │
            ▼
┌────────────────────────────────────┐
│ 3. 記事分類・適切性判定（LLM）     │
│   - 4ステップ検証プロセス          │
│   - 企業関連性・AI/DX内容チェック   │
│   - カテゴリ・業務領域・タグ付与    │
└───────────┬────────────────────────┘
            │
            ▼
      データベース保存
```

### 1. URLレベルフィルタ（research_agent.py）

**目的:** LLM呼び出し前に明らかに不適切な記事を除外

**実装:** `ResearchAgent._process_items_in_order()`

#### リスト記事検出 (`_is_list_article_url()`)

データベース分析から抽出した実際のパターン（17件の不適切記事から導出）:

```python
list_patterns = [
    '/tags/',       # タグ一覧
    '/tag/',        # タグページ
    '/theme/',      # テーマ別一覧
    '/keyword/',    # キーワード一覧
    '/category/',   # カテゴリ一覧
    '/corner/',     # コーナー一覧
    '/case',        # 事例一覧
    '/events',      # イベント一覧
    '/insights',    # インサイト一覧
]

# ドメインルート（/ のみ）も検出
if path == "/" or path == "":
    return True
```

**効果:** 記事一覧ページやまとめページを事前に除外

#### 信頼性の低いソース検出 (`_is_unreliable_source()`)

個人ブログなど信頼性が不明なドメインを除外:

```python
unreliable_domains = [
    'note.com',    # 日本の個人ブログ
    'medium.com',  # 個人ブログ
]
```

**効果:** 信頼性の低い情報源からの記事を事前に除外

### 2. AI関連性判定（llm/relevance.py）

**目的:** AI/DX技術が記事の主題である記事のみを通過させる

**プロンプト:** `prompt_templates.py`

#### 判定基準

**TRUE（AI関連と判定）:**
- 生成AI技術の実装・活用（ChatGPT, Claude, GPT, LLM等）
- 機械学習・深層学習の実装（ニューラルネットワーク, CNN, RNN等）
- AI主導の自動化・意思決定（AIエージェント, AIアシスタント等）
- 具体的なAI活用領域（画像認識, NLP, 音声認識等）

**FALSE（非AI記事）:**
- DX・デジタル化のみ（AI技術の具体的記載なし）
- 一般的なIT技術（クラウド, データベース等）
- AI要素のない自動化（ルールベースRPA等）
- 曖昧な「AI」言及のみ
- その他（IoT, ブロックチェーン等でAI要素なし）

**実装詳細:**
```python
# 本文取得成功時
is_ai_related = await self.ai_classifier.classify_article_content(
    title=title, content=content
)

# 本文取得失敗時（フォールバック）
is_ai_related = await self.ai_classifier.classify_text(
    title=title, snippet=snippet
)
```

### 3. 記事分類・適切性判定（llm/classifier.py）

**目的:** 金融業界・対象企業に関連し、AI/DX内容を含む記事のみを保存

**プロンプト:** `prompt_templates.py` - `CLASSIFIER_SYSTEM_PROMPT`

#### 4ステップ検証プロセス

```
ステップ1: 対象企業の関連性チェック（最優先）
   ├─ 対象企業名が記事本文に明示的に登場するか？
   ├─ 対象企業の具体的な活動・発表・取り組みが主題か？
   └─ NO → is_inappropriate: true（理由: "対象企業への具体的な言及なし"）

ステップ2: AI/DX関連性チェック
   ├─ AI、機械学習、生成AI、LLM、自動化等の具体的技術が実装されているか？
   └─ NO → is_inappropriate: true（理由: "AI/DX技術の具体的な実装なし"）

ステップ3: 記事タイプチェック
   ├─ リスト記事、まとめ記事、一覧ページではないか？
   └─ YES → is_inappropriate: true（理由: "リスト・まとめ記事"）

ステップ4: アクセス・品質チェック
   ├─ 記事本文が取得できているか？
   ├─ 有償サイトやアクセス制限はないか？
   └─ 問題あり → is_inappropriate: true（理由: "本文取得不可/アクセス制限"）

すべてクリア → is_inappropriate: false
```

#### 不適切な記事の判定基準（優先度順）

**a) 企業無関係（最重要）**
- 対象企業名が記事本文に1回も出現しない
- 対象企業への言及が脚注や参考程度のみ
- 他の企業の事例のみ
- 業界全体の話題で対象企業が第三者的・客観的にしか登場しない

**b) AI/DX内容なし**
- AI、機械学習、生成AI、LLM、自動化、デジタル化などの具体的技術への言及がない
- 単なる「スマート」「デジタル」「IT」のみ
- 一般的なシステム更新やインフラ整備のみ

**c) リスト・まとめ記事**
- URLに「list」「ranking」「matome」「summary」が含まれる
- 複数企業の事例を羅列しているだけ
- 記事一覧ページ、ニュースサイトのトップページ

**d) アクセス・信頼性の問題**
- 有償会員限定、ペイウォール
- Mediumなどの個人ブログで信頼性が不明
- 404エラー、アクセス不可
- 動画のみで文字コンテンツなし

**e) 重複・既知**
- 明らかに同じ内容の記事

**f) その他の不適切**
- 金融業界と無関係な業界の話題
- 求人情報のみ（AI人材の求人は対象）

### データベース分析結果

**分析対象:** 635件の不適切記事

**パターン分布:**
- 企業無関係: 306件 (48.2%)
- その他: 141件 (22.2%)
- 理由なし: 63件 (9.9%)
- AI内容なし: 55件 (8.7%)
- 調査済・対象外: 33件 (5.2%)
- アクセス不可: 20件 (3.1%)
- リスト記事: 17件 (2.7%)

**改善の根拠:** 上記の実データ分析に基づき、各フィルタリング層を設計・実装

### パフォーマンスへの影響

**URLレベルフィルタの効果:**
- LLM呼び出し削減: リスト記事・個人ブログ記事を事前除外
- コスト削減: 不要なAPI呼び出しを回避
- 処理時間短縮: 早期除外により全体の処理時間を削減

**LLMフィルタの効果:**
- データ品質向上: 高精度な判定により適切な記事のみを保存
- ストレージ効率化: 不適切な記事をデータベースに保存しない

---

**Document Version:** 3.0
**Last Updated:** 2026-01-12
**Author:** AI Case Study Research System Team
